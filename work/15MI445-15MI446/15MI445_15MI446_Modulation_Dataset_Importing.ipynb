{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "o8oK85zxvbsT"
   },
   "source": [
    "## Submitted by Animesh Srivastava (15MI445) and Sumit Kumar (15MI446)\n",
    "## Data Loading Notebook\n",
    "This notebook loads data from dataset file then saves numpy arrays into tensorflow dataset files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "k0z8bCgrv4hv"
   },
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import _pickle as cPickle\n",
    "import sys \n",
    "import matplotlib.pyplot as plt\n",
    "import scipy as sp\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "import tensorflow as tf\n",
    "import gc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tLZVXqD1wAxO"
   },
   "source": [
    "## Understanding dataset\n",
    "\n",
    "The dataset we have created is generated with GNU Radio, consisting of 11 modulations. This is a variable-SNR dataset with moderate LO drift, light fading, and numerous different labeled SNR increments for use in measuring performance across different signal and noise power scenarios.\n",
    "The dataset created has a size of 100 MB."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UmLG2ff4wJiK"
   },
   "source": [
    "## Loading data\n",
    "\n",
    "The file is formatted as a \"pickle\" file which can be open for example in python by using cPickle.load(...)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "L6n6UgbKv8-J",
    "outputId": "f13f5fcf-36a9-4d1e-ec60-08afc3dfaaea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "#Loading the data from google drive \n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "filename = \"/content/drive/My Drive/moddata_dict.dat\"\n",
    "open_file = open(filename,'rb')\n",
    "data = cPickle.load(open_file, encoding='latin1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zE7v3-nwwb7i"
   },
   "source": [
    "## Loading to Numpy arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "w2h6Z4SBwQIk",
    "outputId": "fc48f758-8a0e-4cc2-d3d8-1d1a62608cba"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "119"
      ]
     },
     "execution_count": 49,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use lists when accessing data from dict for ease of access.\n",
    "keys_list = list(data.keys())\n",
    "temp_list = []\n",
    "label_list = []\n",
    "for i in range(len(keys_list)):\n",
    "    curr_item = data[keys_list[i]] \n",
    "    temp_list.append(curr_item)\n",
    "    for j in range(curr_item.shape[0]):\n",
    "        label_list.append(keys_list[i])\n",
    "        \n",
    "# Convert all lists into numpy arrays.\n",
    "X = np.array(temp_list).reshape(1200000,2,128)\n",
    "Y = np.array(label_list)\n",
    "\n",
    "# Clear All un-neccsarry lists created.\n",
    "temp_list.clear()\n",
    "label_list.clear()\n",
    "keys_list.clear()\n",
    "data.clear()\n",
    "del(data)\n",
    "del(temp_list)\n",
    "del(label_list)\n",
    "del(keys_list)\n",
    "del(curr_item)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "9n8mZdFz_FXo",
    "outputId": "8792ef69-d9a2-4e7c-98d3-dfb8fe8d20fe"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 50,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1-np5PxV16NV"
   },
   "source": [
    "## Splitting data\n",
    "\n",
    "Split the data into 50% for training/validation and 50% for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fR0eFSmUQAth"
   },
   "outputs": [],
   "source": [
    "def split_data(X,Y,dataset_name): \n",
    "  (trainX, testX, trainY, testY) = train_test_split(X,Y, test_size=0.50, random_state=42)\n",
    "  lb=LabelBinarizer()\n",
    "  lb.fit_transform(trainY[:,0])\n",
    "#   del(testX)\n",
    "#   del(testY)\n",
    "#   gc.collect()\n",
    "  #(trainX, valX, trainY, valY) = train_test_split(trainX,trainY, test_size=0.05, random_state=42)\n",
    "  del(trainX)\n",
    "  del(trainY)\n",
    "  gc.collect()\n",
    "  np.save('/content/drive/My Drive/'+dataset_name+'_SNR.npy',testY[:,1])\n",
    "  #return trainX,lb.fit_transform(trainY[:,0]),testX,lb.transform(testY[:,0]),valX,lb.transform(valY[:,0])\n",
    "\n",
    "  return testX,lb.transform(testY[:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Uk6JrP96FKFH"
   },
   "source": [
    "## Creating a tensorflow record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mD-u3EdwFMpu"
   },
   "outputs": [],
   "source": [
    "def convert_data_2(data,labels,filename):\n",
    "   with tf.python_io.TFRecordWriter('/content/drive/My Drive/TFDatasets/'+filename+'.tfrecord') as writer:\n",
    "            for i in range(data.shape[0]):\n",
    "                example =convert_signal(data[i],labels[i])  \n",
    "                writer.write(example.SerializeToString())\n",
    "\n",
    "def convert_signal_2(signal,label):\n",
    "  example = tf.train.Example(features = tf.train.Features(feature = {\n",
    "            'feature1': tf.train.Feature(float_list = tf.train.FloatList(value = signal[0].tolist())),\n",
    "            'feature2': tf.train.Feature(float_list = tf.train.FloatList(value = signal[1].tolist())),\n",
    "            'label': tf.train.Feature(int64_list = tf.train.Int64List(value = label.tolist()))\n",
    "  }))\n",
    "  return example\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "33sSMk7Tw-AC"
   },
   "outputs": [],
   "source": [
    "def convert_data_4(data,labels,filename):\n",
    "   with tf.python_io.TFRecordWriter('/content/drive/My Drive/TFDatasets/'+filename+'.tfrecord') as writer:\n",
    "            for i in range(data.shape[0]):\n",
    "                example =convert_signal_4(data[i],labels[i])  \n",
    "                writer.write(example.SerializeToString())\n",
    "\n",
    "def convert_signal_4(signal,label):\n",
    "  example = tf.train.Example(features = tf.train.Features(feature = {\n",
    "            'feature1': tf.train.Feature(float_list = tf.train.FloatList(value = signal[0].tolist())),\n",
    "            'feature2': tf.train.Feature(float_list = tf.train.FloatList(value = signal[1].tolist())),\n",
    "            'feature3': tf.train.Feature(float_list = tf.train.FloatList(value = signal[2].tolist())),\n",
    "            'feature4': tf.train.Feature(float_list = tf.train.FloatList(value = signal[3].tolist())),\n",
    "            'label': tf.train.Feature(int64_list = tf.train.Int64List(value = label.tolist()))\n",
    "  }))\n",
    "  return example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Oe9niSKj8D2N"
   },
   "outputs": [],
   "source": [
    "def convert_data_6(data,labels,filename):\n",
    "   with tf.python_io.TFRecordWriter('/content/drive/My Drive/TFDatasets/'+filename+'.tfrecord') as writer:\n",
    "            for i in range(data.shape[0]):\n",
    "                example =convert_signal_6(data[i],labels[i])  \n",
    "                writer.write(example.SerializeToString())\n",
    "\n",
    "def convert_signal_6(signal,label):\n",
    "  example = tf.train.Example(features = tf.train.Features(feature = {\n",
    "            'feature1': tf.train.Feature(float_list = tf.train.FloatList(value = signal[0].tolist())),\n",
    "            'feature2': tf.train.Feature(float_list = tf.train.FloatList(value = signal[1].tolist())),\n",
    "            'feature3': tf.train.Feature(float_list = tf.train.FloatList(value = signal[2].tolist())),\n",
    "            'feature4': tf.train.Feature(float_list = tf.train.FloatList(value = signal[3].tolist())),\n",
    "            'feature5': tf.train.Feature(float_list = tf.train.FloatList(value = signal[4].tolist())),\n",
    "            'feature6': tf.train.Feature(float_list = tf.train.FloatList(value = signal[5].tolist())),\n",
    "            'label': tf.train.Feature(int64_list = tf.train.Int64List(value = label.tolist()))\n",
    "  }))\n",
    "  return example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "WL0AtrXI8PjM",
    "outputId": "7236b34c-e2e4-4431-b746-bc3830405e2b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 56,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5wPLYuFfwndS"
   },
   "source": [
    "## Create feature Spaces for data\n",
    "\n",
    "Every sample is presented using two vectors each of them has 128 elements. Those two vectors are the in-phase and quadrature phase components of a sample.\n",
    "\n",
    "X array consists of those two raw features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TtWEKVg9IzFE"
   },
   "source": [
    "### Raw Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iQT9vRmg8lc2"
   },
   "outputs": [],
   "source": [
    "#split the data into test, train and validation sets.\n",
    "(trainX, trainY, testX, testY, valX, valY) = split_data(X,Y,'raw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "H9ALEQ458nrw"
   },
   "outputs": [],
   "source": [
    "convert_data(trainX,trainY,'raw_train_data')\n",
    "convert_data(testX,testY,'raw_test_data')\n",
    "convert_data(valX,valY,'raw_val_data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zDHltCOMw9H2"
   },
   "source": [
    "### Integration Features (2 features)\n",
    "One for the in-phase component and one for quadrature phase component."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "so_pAM4UwjY0"
   },
   "outputs": [],
   "source": [
    "int_X = np.apply_along_axis(lambda column:np.hstack((0,column)),2,np.apply_along_axis(lambda column:sp.integrate.cumtrapz(column,dx=1,axis=-1),2,X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3cNr6uRpUUoZ"
   },
   "outputs": [],
   "source": [
    "del(X)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Yi4UxxNR402a"
   },
   "outputs": [],
   "source": [
    "#split the data into test, train and validation sets.\n",
    "(trainX, trainY, testX, testY, valX, valY) = split_data(int_X,Y,'int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BnSMKMuT9oy1"
   },
   "outputs": [],
   "source": [
    "convert_data(trainX,trainY,'int_train_data')\n",
    "convert_data(testX,testY,'int_test_data')\n",
    "convert_data(valX,valY,'int_val_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "StYta_1yVsSh",
    "outputId": "385700cc-45de-4fc7-9f01-51fc21fc7632"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "453"
      ]
     },
     "execution_count": 13,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del(int_X)\n",
    "del(trainX,trainY,testX, testY, valX, valY)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wrCJM5xdxQYx"
   },
   "source": [
    "### Derivative Features (2 features)\n",
    "One for the in-phase component and one for quadrature phase component."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0IhHmyycxiGB"
   },
   "outputs": [],
   "source": [
    "der_X = np.apply_along_axis(lambda column:np.gradient(column),2,X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "C_AkQ0aSVTYW",
    "outputId": "63707676-7a18-43ae-eb46-d368ca5aef44"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 18,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del(X)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JyxOQRJo5Ll4"
   },
   "outputs": [],
   "source": [
    "#split the data into test, train and validation sets.\n",
    "(trainX, trainY, testX, testY, valX, valY) = split_data(der_X,Y,'der')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "C7WsJpOK9uxX"
   },
   "outputs": [],
   "source": [
    "convert_data(trainX,trainY,'der_train_data')\n",
    "convert_data(testX,testY,'der_test_data')\n",
    "convert_data(valX,valY,'der_val_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "vjejxWnlXGDZ",
    "outputId": "3bc1da76-a7b1-42bc-90dc-47869ac63a4d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "288"
      ]
     },
     "execution_count": 22,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del(der_X)\n",
    "del(trainX,trainY,testX, testY, valX, valY)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KSQzMJtUxodR"
   },
   "source": [
    "### Combination 1: Derivative Features + Raw Features (4 features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_Uref8qYyEIH"
   },
   "outputs": [],
   "source": [
    "com_one_X = np.concatenate((np.apply_along_axis(lambda column:np.gradient(column),2,X),X),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xwxLvij65NQp"
   },
   "outputs": [],
   "source": [
    "#split the data into test, train and validation sets.\n",
    "(trainX, trainY, testX, testY, valX, valY) = split_data(com_one_X,Y,'com_one')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3d11n7c394dz"
   },
   "outputs": [],
   "source": [
    "convert_data_4(trainX,trainY,'com1_train_data')\n",
    "convert_data_4(testX,testY,'com1_test_data')\n",
    "convert_data_4(valX,valY,'com1_val_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "R2TNu3pYXPPL",
    "outputId": "a441d328-bb14-4067-95a2-6eec172b5ad0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 12,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#del(X)\n",
    "#del(trainX,trainY,testX, testY, valX, valY)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "o0pUts7PyPnW"
   },
   "source": [
    "### Combination 2: Integration Features + Raw Features (4 features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "P3ItEiddyUVW"
   },
   "outputs": [],
   "source": [
    "com_two_X = np.concatenate((np.apply_along_axis(lambda column:np.hstack((0,column)),2,np.apply_along_axis(lambda column:sp.integrate.cumtrapz(column,dx=1,axis=-1),2,X)),X),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KdrN8_ke5QpR"
   },
   "outputs": [],
   "source": [
    "#split the data into test, train and validation sets.\n",
    "(testX,testY) = split_data(com_two_X,Y,'com_two')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "7vbvrT7cZlWp",
    "outputId": "9fa48a4f-c2a7-4425-d164-12a3f9952e7a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del(X)\n",
    "#del(trainX,trainY)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "SF0_r0yY3bNT",
    "outputId": "7399ca9c-08aa-4c88-c6ec-531659a82bfb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 23,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nsdcKEdw-F3f"
   },
   "outputs": [],
   "source": [
    "#convert_data_4(trainX,trainY,'com2_train_data')\n",
    "convert_data_4(testX,testY,'com2_test_data')\n",
    "#convert_data_4(valX,valY,'com2_val_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "0UwrEw8JZegy",
    "outputId": "204360be-7fe9-408c-de39-5d98262545c0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 12,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#del(com_two_X)\n",
    "#del(trainX,trainY,valX, valY)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bZIiyp6Zyalt"
   },
   "source": [
    "### Combination 3: Integration Features + Derivative Features (4 features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "s92NrwdIyffb"
   },
   "outputs": [],
   "source": [
    "com_three_X = np.concatenate((np.apply_along_axis(lambda column:np.gradient(column),2,X)\n",
    "                              ,np.apply_along_axis(lambda column:np.hstack((0,column)),2,np.apply_along_axis(lambda column:sp.integrate.cumtrapz(column,dx=1,axis=-1),2,X))),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Zvhzj5rVClLf",
    "outputId": "e8dc22fc-676c-4812-9a38-002d776626ff"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 25,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del(X)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Vflwu9T35S_f"
   },
   "outputs": [],
   "source": [
    "#split the data into test, train and validation sets.\n",
    "(testX,testY) = split_data(com_three_X,Y, 'com_three')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "NyHBPwj25Mrd",
    "outputId": "9e59cfea-c351-40b1-ff2b-003ef6765e96"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 41,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pdeGEKfV-vg7"
   },
   "outputs": [],
   "source": [
    "#convert_data_4(trainX,trainY,'com3_train_data')\n",
    "convert_data_4(testX,testY,'com3_test_data')\n",
    "#convert_data_4(valX,valY,'com3_val_data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sueeHFn1yhN0"
   },
   "source": [
    "### Combination 4: Integration Features + Derivative Features + Raw Features (6 features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "boY7myzEyo1m"
   },
   "outputs": [],
   "source": [
    "com_four_X = np.concatenate((np.apply_along_axis(lambda column:np.gradient(column),2,X)\n",
    "                              ,np.apply_along_axis(lambda column:np.hstack((0,column)),2,np.apply_along_axis(lambda column:sp.integrate.cumtrapz(column,dx=1,axis=-1),2,X)),X),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "og2vV31255cY",
    "outputId": "bfe3212e-92df-4409-db49-9980be86aa77"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 60,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del(X)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rYypnvQzaFdM"
   },
   "outputs": [],
   "source": [
    "dat_int_der_raw=np.load('/content/drive/My Drive/X_rawdiffinteg.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KjmQ68M55aCH"
   },
   "outputs": [],
   "source": [
    "#split the data into test, train and validation sets.\n",
    "(trainX, trainY, testX, testY, valX, valY) = split_data(dat_int_der_raw,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UiL8dhQy-zMk"
   },
   "outputs": [],
   "source": [
    "convert_data(trainX,trainY,'com4_train_data')\n",
    "convert_data(testX,testY,'com4_test_data')\n",
    "convert_data(valX,valY,'com4_val_data')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "TtWEKVg9IzFE",
    "zDHltCOMw9H2",
    "wrCJM5xdxQYx",
    "KSQzMJtUxodR",
    "o0pUts7PyPnW"
   ],
   "name": "Copy of Copy of Modulation_Recognition_Data.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
